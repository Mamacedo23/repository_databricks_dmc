{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40cd8367-a2f3-4903-a0ee-8653a879f82d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, coalesce, to_date, substring, initcap, trim, col, lit, lower, current_timestamp, concat, upper, to_timestamp\n",
    "from pyspark.sql.types import LongType, StringType, DateType, TimestampType\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd094fe6-d7ab-4c8d-ad93-418cc1122ee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_fecha_devolucion_safe(fecha_col: str):\n",
    "   \n",
    "    col_trimmed = trim(col(fecha_col))\n",
    "    \n",
    "    return coalesce(\n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{4}-\\\\d{2}-\\\\d{2} \\\\d{2}:\\\\d{2}:\\\\d{2}$\"),\n",
    "               to_timestamp(col_trimmed, 'yyyy-MM-dd HH:mm:ss')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{2}/\\\\d{2}/\\\\d{4} \\\\d{2}:\\\\d{2}:\\\\d{2}$\"),\n",
    "               to_timestamp(col_trimmed, 'dd/MM/yyyy HH:mm:ss')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{2}-\\\\d{2}-\\\\d{4} \\\\d{2}:\\\\d{2}:\\\\d{2}$\"),\n",
    "               to_timestamp(col_trimmed, 'MM-dd-yyyy HH:mm:ss')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{4}/\\\\d{2}/\\\\d{2} \\\\d{2}:\\\\d{2}:\\\\d{2}$\"),\n",
    "               to_timestamp(col_trimmed, 'yyyy/MM/dd HH:mm:ss')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\"),\n",
    "               to_timestamp(col_trimmed, 'yyyy-MM-dd')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{2}/\\\\d{2}/\\\\d{4}$\"),\n",
    "               to_timestamp(col_trimmed, 'dd/MM/yyyy')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{2}/\\\\d{2}/\\\\d{4}$\"),\n",
    "               to_timestamp(col_trimmed, 'MM/dd/yyyy')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{2}-\\\\d{2}-\\\\d{4}$\"),\n",
    "               to_timestamp(col_trimmed, 'MM-dd-yyyy')),\n",
    "        \n",
    "        \n",
    "        when(col_trimmed.rlike(\"^\\\\d{2}-\\\\d{2}-\\\\d{4}$\"),\n",
    "               to_timestamp(col_trimmed, 'dd-MM-yyyy')),\n",
    "        \n",
    "        lit(None).cast(TimestampType())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ea10665-4436-4a7e-a902-872e95a07368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"webinar\"\n",
    "fecha_actual = datetime.now().date()\n",
    "\n",
    "df = (\n",
    "    spark.table(f\"{catalog_name}.bronze.devoluciones\")\n",
    "    .withColumn(\"motivo_temp\",\n",
    "        when(col(\"motivo\").isNull(), None)\n",
    "        .when(trim(col(\"motivo\")) == \"N/A\", None)\n",
    "        .when(trim(col(\"motivo\")) == \"\", None)\n",
    "        .otherwise(lower(trim(col(\"motivo\"))))\n",
    "    )\n",
    "    .withColumn(\"motivo\",\n",
    "        when(col(\"motivo_temp\").isNull(), None)\n",
    "        .otherwise(\n",
    "            concat(\n",
    "                upper(substring(col(\"motivo_temp\"), 1, 1)),\n",
    "                substring(col(\"motivo_temp\"), 2, 1000)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    .drop(\"motivo_temp\")\n",
    "    .withColumn(\"fecha_devolucion\",\n",
    "        parse_fecha_devolucion_safe(\"fecha_devolucion\")\n",
    "    )\n",
    "    .withColumn(\"fecha_devolucion\",\n",
    "        when(\n",
    "            (col(\"fecha_devolucion\") > lit(fecha_actual)) | \n",
    "            (col(\"fecha_devolucion\") < lit(\"2000-01-01\")),\n",
    "            None\n",
    "        )\n",
    "        .otherwise(col(\"fecha_devolucion\"))\n",
    "    )\n",
    "    .dropDuplicates([\"id_devolucion\"])\n",
    "    .withColumn(\"updated_at\", current_timestamp())\n",
    "    .select(\n",
    "        col(\"id_devolucion\").cast(LongType()),\n",
    "        col(\"id_venta\").cast(LongType()),\n",
    "        col(\"motivo\").cast(StringType()),\n",
    "        col(\"fecha_devolucion\").cast(TimestampType()),\n",
    "        col(\"updated_at\")\n",
    "    )\n",
    ")\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog_name}.silver.devoluciones\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "devoluciones",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
